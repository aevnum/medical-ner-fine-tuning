{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75557327",
   "metadata": {},
   "source": [
    "### 0. Project Configuration & Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6782e577",
   "metadata": {},
   "source": [
    "#### 0.1 Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39d6ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 0.1 IMPORT LIBRARIES\n",
    "# ============================================================================\n",
    "\n",
    "# Standard Libraries\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import random\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "from collections import Counter, defaultdict\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "\n",
    "# Data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Progress bars\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Machine Learning & NLP\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Transformers & Datasets\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForTokenClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorForTokenClassification,\n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "\n",
    "# Evaluation\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    precision_recall_fscore_support\n",
    ")\n",
    "from seqeval.metrics import (\n",
    "    classification_report as seqeval_classification_report,\n",
    "    f1_score as seqeval_f1_score,\n",
    "    precision_score as seqeval_precision_score,\n",
    "    recall_score as seqeval_recall_score\n",
    ")\n",
    "\n",
    "# Weights & Biases for experiment tracking\n",
    "import wandb\n",
    "\n",
    "# Set style for visualizations\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Check GPU availability\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "\n",
    "print(\"\\n✓ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e75a6c",
   "metadata": {},
   "source": [
    "#### 0.2 Configuration Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c9747b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 0.2 CONFIGURATION CONSTANTS\n",
    "# ============================================================================\n",
    "\n",
    "# Project Information\n",
    "PROJECT_NAME = \"Medical_Entity_Recognition_Linking\"\n",
    "\n",
    "# Timestamp for experiment tracking\n",
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "EXPERIMENT_NAME = f\"MERL_{TIMESTAMP}\"\n",
    "\n",
    "# Dataset Configuration\n",
    "DATASET_NAME = \"ktgiahieu/maccrobat2018_2020\"\n",
    "DATASET_SPLIT_SIZES = {\n",
    "    'train': 340,\n",
    "    'validation': 30,\n",
    "    'test': 30\n",
    "}\n",
    "\n",
    "# Model Configuration\n",
    "MODEL_CONFIGS = {\n",
    "    'pubmedbert': {\n",
    "        'name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract-fulltext',\n",
    "        'display_name': 'PubMedBERT'\n",
    "    },\n",
    "    'biobert': {\n",
    "        'name': 'dmis-lab/biobert-v1.1',\n",
    "        'display_name': 'BioBERT'\n",
    "    },\n",
    "    'bioformer': {\n",
    "        'name': 'bioformers/bioformer-16L',\n",
    "        'display_name': 'Bioformer-16L'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Primary model for baseline\n",
    "PRIMARY_MODEL = 'pubmedbert'\n",
    "PRIMARY_MODEL_NAME = MODEL_CONFIGS[PRIMARY_MODEL]['name']\n",
    "\n",
    "# Training Hyperparameters\n",
    "TRAINING_CONFIG = {\n",
    "    'learning_rate': 2e-5,\n",
    "    'batch_size': 16,\n",
    "    'num_epochs': 5,\n",
    "    'warmup_steps': 500,\n",
    "    'weight_decay': 0.01,\n",
    "    'gradient_accumulation_steps': 1,\n",
    "    'fp16': torch.cuda.is_available(),  # Use mixed precision if GPU available\n",
    "    'logging_steps': 50,\n",
    "    'eval_steps': 100,\n",
    "    'save_steps': 100,\n",
    "    'save_total_limit': 2,\n",
    "    'load_best_model_at_end': True,\n",
    "    'metric_for_best_model': 'f1',\n",
    "    'greater_is_better': True\n",
    "}\n",
    "\n",
    "# Entity Type Tiers (from EDA)\n",
    "ENTITY_TIERS = {\n",
    "    'frequent': [\n",
    "        'Age', 'Diagnostic_procedure', 'Sign_symptom', 'Lab_value',\n",
    "        'Biological_structure', 'Detailed_description', 'Date',\n",
    "        'Disease_disorder', 'History', 'Therapeutic_procedure',\n",
    "        'Medication', 'Dosage', 'Duration', 'Clinical_event',\n",
    "        'Nonbiological_location'\n",
    "    ],\n",
    "    'medium': [\n",
    "        'Family_history', 'Coreference', 'Sex', 'Distance', 'Other_entity',\n",
    "        'Area', 'Volume', 'Time', 'Frequency', 'Activity', 'Other_event',\n",
    "        'Personal_background', 'Administration'\n",
    "    ],\n",
    "    'rare': [\n",
    "        'Subject', 'Occupation', 'Outcome', 'Shape', 'Severity',\n",
    "        'Qualitative_concept', 'Quantitative_concept', 'Texture',\n",
    "        'Color', 'Height', 'Weight', 'Biological_attribute', 'Mass'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# High-value entities for medical coding (production focus)\n",
    "HIGH_VALUE_ENTITIES = [\n",
    "    'Disease_disorder',\n",
    "    'Therapeutic_procedure',\n",
    "    'Medication',\n",
    "    'Sign_symptom',\n",
    "    'Diagnostic_procedure'\n",
    "]\n",
    "\n",
    "# Confidence Thresholds to Test\n",
    "CONFIDENCE_THRESHOLDS = [0.5, 0.6, 0.7, 0.8, 0.85, 0.9, 0.95]\n",
    "\n",
    "# Output Directories\n",
    "OUTPUT_DIR = f\"./outputs/{EXPERIMENT_NAME}\"\n",
    "MODEL_SAVE_DIR = f\"{OUTPUT_DIR}/models\"\n",
    "RESULTS_DIR = f\"{OUTPUT_DIR}/results\"\n",
    "PLOTS_DIR = f\"{OUTPUT_DIR}/plots\"\n",
    "\n",
    "# Create directories\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(MODEL_SAVE_DIR, exist_ok=True)\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "os.makedirs(PLOTS_DIR, exist_ok=True)\n",
    "\n",
    "# Random Seeds for Reproducibility\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "def set_seed(seed: int = RANDOM_SEED):\n",
    "    \"\"\"Set random seeds for reproducibility\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(RANDOM_SEED)\n",
    "\n",
    "# Display Configuration\n",
    "print(\"=\"*80)\n",
    "print(f\"PROJECT: {PROJECT_NAME}\")\n",
    "print(f\"EXPERIMENT: {EXPERIMENT_NAME}\")\n",
    "print(f\"TIMESTAMP: {TIMESTAMP}\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nPrimary Model: {MODEL_CONFIGS[PRIMARY_MODEL]['display_name']}\")\n",
    "print(f\"Model Path: {PRIMARY_MODEL_NAME}\")\n",
    "print(f\"\\nDataset: {DATASET_NAME}\")\n",
    "print(f\"Train: {DATASET_SPLIT_SIZES['train']} | \"\n",
    "      f\"Val: {DATASET_SPLIT_SIZES['validation']} | \"\n",
    "      f\"Test: {DATASET_SPLIT_SIZES['test']}\")\n",
    "print(f\"\\nTraining Config:\")\n",
    "for key, value in TRAINING_CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "print(f\"\\nOutput Directory: {OUTPUT_DIR}\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\n✓ Configuration loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2954d963",
   "metadata": {},
   "source": [
    "#### 0.3 WandB Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28003171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 0.3 WANDB INITIALIZATION\n",
    "# ============================================================================\n",
    "\n",
    "# Method 1: Using Kaggle Secrets (if available)\n",
    "try:\n",
    "    from kaggle_secrets import UserSecretsClient\n",
    "    user_secrets = UserSecretsClient()\n",
    "    wandb_api_key = user_secrets.get_secret(\"WANDB_API_KEY\")\n",
    "    os.environ['WANDB_API_KEY'] = wandb_api_key\n",
    "    print(\"✓ WandB API key loaded from Kaggle Secrets\")\n",
    "except:\n",
    "    print(\"⚠ Kaggle Secrets not available. WandB will prompt for login.\")\n",
    "    print(\"  You can manually set: os.environ['WANDB_API_KEY'] = 'your_key_here'\")\n",
    "\n",
    "# Initialize WandB\n",
    "try:\n",
    "    # Login to WandB\n",
    "    wandb.login()\n",
    "    \n",
    "    # Initialize WandB project\n",
    "    wandb.init(\n",
    "        project=PROJECT_NAME,\n",
    "        name=EXPERIMENT_NAME,\n",
    "        config={\n",
    "            \"model_name\": PRIMARY_MODEL_NAME,\n",
    "            \"dataset\": DATASET_NAME,\n",
    "            \"timestamp\": TIMESTAMP,\n",
    "            **TRAINING_CONFIG,\n",
    "            \"entity_tiers\": ENTITY_TIERS,\n",
    "            \"high_value_entities\": HIGH_VALUE_ENTITIES,\n",
    "            \"random_seed\": RANDOM_SEED\n",
    "        },\n",
    "        tags=[PRIMARY_MODEL],\n",
    "        notes=f\"Baseline NER model training on MACCROBAT dataset. \"\n",
    "              f\"Focus: production-readiness metrics and error analysis.\"\n",
    "    )\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(f\"✓ WandB initialized successfully!\")\n",
    "    print(f\"  Project: {PROJECT_NAME}\")\n",
    "    print(f\"  Run Name: {EXPERIMENT_NAME}\")\n",
    "    print(f\"  Dashboard: {wandb.run.get_url()}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    WANDB_ENABLED = True\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"⚠ WandB initialization failed: {e}\")\n",
    "    print(\"  Continuing without WandB logging...\")\n",
    "    WANDB_ENABLED = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64b3485",
   "metadata": {},
   "source": [
    "#### 0.4 Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71db34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 0.4 HELPER FUNCTIONS\n",
    "# ============================================================================\n",
    "\n",
    "def log_to_wandb(data: Dict, step: Optional[int] = None, commit: bool = True):\n",
    "    \"\"\"\n",
    "    Safely log data to WandB if enabled\n",
    "    \n",
    "    Args:\n",
    "        data: Dictionary of metrics to log\n",
    "        step: Optional step number\n",
    "        commit: Whether to commit the log immediately\n",
    "    \"\"\"\n",
    "    if WANDB_ENABLED:\n",
    "        try:\n",
    "            wandb.log(data, step=step, commit=commit)\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Failed to log to WandB: {e}\")\n",
    "\n",
    "\n",
    "def save_results(data: Dict, filename: str, directory: str = RESULTS_DIR):\n",
    "    \"\"\"\n",
    "    Save results to JSON file\n",
    "    \n",
    "    Args:\n",
    "        data: Dictionary to save\n",
    "        filename: Name of the file (with .json extension)\n",
    "        directory: Directory to save to\n",
    "    \"\"\"\n",
    "    filepath = os.path.join(directory, filename)\n",
    "    with open(filepath, 'w') as f:\n",
    "        json.dump(data, f, indent=2)\n",
    "    print(f\"✓ Results saved to: {filepath}\")\n",
    "    \n",
    "    # Also log to WandB as artifact\n",
    "    if WANDB_ENABLED:\n",
    "        try:\n",
    "            artifact = wandb.Artifact(\n",
    "                name=filename.replace('.json', ''),\n",
    "                type='results'\n",
    "            )\n",
    "            artifact.add_file(filepath)\n",
    "            wandb.log_artifact(artifact)\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Failed to log artifact to WandB: {e}\")\n",
    "\n",
    "\n",
    "def save_plot(fig, filename: str, directory: str = PLOTS_DIR, dpi: int = 300):\n",
    "    \"\"\"\n",
    "    Save matplotlib figure and log to WandB\n",
    "    \n",
    "    Args:\n",
    "        fig: Matplotlib figure object\n",
    "        filename: Name of the file (with extension)\n",
    "        directory: Directory to save to\n",
    "        dpi: Resolution for saved figure\n",
    "    \"\"\"\n",
    "    filepath = os.path.join(directory, filename)\n",
    "    fig.savefig(filepath, dpi=dpi, bbox_inches='tight')\n",
    "    print(f\"✓ Plot saved to: {filepath}\")\n",
    "    \n",
    "    # Log to WandB\n",
    "    if WANDB_ENABLED:\n",
    "        try:\n",
    "            wandb.log({filename.replace('.png', ''): wandb.Image(filepath)})\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Failed to log plot to WandB: {e}\")\n",
    "    \n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def format_time(seconds: float) -> str:\n",
    "    \"\"\"Format seconds into human-readable time string\"\"\"\n",
    "    if seconds < 60:\n",
    "        return f\"{seconds:.2f}s\"\n",
    "    elif seconds < 3600:\n",
    "        minutes = seconds / 60\n",
    "        return f\"{minutes:.2f}m\"\n",
    "    else:\n",
    "        hours = seconds / 3600\n",
    "        return f\"{hours:.2f}h\"\n",
    "\n",
    "\n",
    "def print_gpu_memory():\n",
    "    \"\"\"Print current GPU memory usage\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        allocated = torch.cuda.memory_allocated() / 1024**3\n",
    "        reserved = torch.cuda.memory_reserved() / 1024**3\n",
    "        print(f\"GPU Memory - Allocated: {allocated:.2f}GB | Reserved: {reserved:.2f}GB\")\n",
    "\n",
    "\n",
    "def create_summary_table(results_dict: Dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create a formatted summary table from results dictionary\n",
    "    \n",
    "    Args:\n",
    "        results_dict: Dictionary with model names as keys and metrics as values\n",
    "    \n",
    "    Returns:\n",
    "        Pandas DataFrame with formatted results\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(results_dict).T\n",
    "    df = df.round(4)\n",
    "    return df\n",
    "\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"✓ Helper functions defined successfully!\")\n",
    "print(\"\\nAvailable functions:\")\n",
    "print(\"  - log_to_wandb(): Log metrics to WandB\")\n",
    "print(\"  - save_results(): Save results to JSON\")\n",
    "print(\"  - save_plot(): Save and log matplotlib figures\")\n",
    "print(\"  - format_time(): Convert seconds to readable format\")\n",
    "print(\"  - print_gpu_memory(): Check GPU usage\")\n",
    "print(\"  - create_summary_table(): Format results as DataFrame\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241a4f94",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948291bd",
   "metadata": {},
   "source": [
    "### 1. Environment Setup & Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94207b02",
   "metadata": {},
   "source": [
    "#### 1.1 Load MACCROBAT Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93b0249",
   "metadata": {},
   "source": [
    "#### 1.2 Dataset Structure Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32e4b17",
   "metadata": {},
   "source": [
    "#### 1.3 Tag Mapping Creation (tag2id, id2tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12be8c2",
   "metadata": {},
   "source": [
    "#### 1.4 Entity Type Tier Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce04bc9c",
   "metadata": {},
   "source": [
    "#### 1.5 Dataset Splitting (Train/Val/Test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf77cb28",
   "metadata": {},
   "source": [
    "#### 1.6 Tokenization & Data Collator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70fddab",
   "metadata": {},
   "source": [
    "#### 1.7 Evaluation Metrics Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139a5a43",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8195f687",
   "metadata": {},
   "source": [
    "### 2. Baseline Model: PubMedBERT Fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8834c73",
   "metadata": {},
   "source": [
    "#### 2.1 Model & Tokenizer Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f6a45d",
   "metadata": {},
   "source": [
    "#### 2.2 Training Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdba8dc6",
   "metadata": {},
   "source": [
    "#### 2.3 Training Loop with WandB Logging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da386c7e",
   "metadata": {},
   "source": [
    "#### 2.4 Model Evaluation on Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc5b47e",
   "metadata": {},
   "source": [
    "#### 2.5 Save Model Artifacts to WandB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09184fef",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641cefb4",
   "metadata": {},
   "source": [
    "### 3. Additional Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f78e33",
   "metadata": {},
   "source": [
    "#### 3.1 BioBERT Fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9076d63",
   "metadata": {},
   "source": [
    "#### 3.2 Alternative Model Training (Bioformer/ClinicalBERT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23e9bcd",
   "metadata": {},
   "source": [
    "#### 3.3 Model Comparison Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6747f70d",
   "metadata": {},
   "source": [
    "#### 3.4 Best Model Selection Criteria"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d009319",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f54cf5",
   "metadata": {},
   "source": [
    "### 4. Per-Entity-Type Performance Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0faef815",
   "metadata": {},
   "source": [
    "#### 4.1 Extract Predictions by Entity Type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3879b9ad",
   "metadata": {},
   "source": [
    "#### 4.2 Calculate Metrics per Entity Type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601613c8",
   "metadata": {},
   "source": [
    "#### 4.3 Tier-Based Analysis (Frequent/Medium/Rare)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6da50e0",
   "metadata": {},
   "source": [
    "#### 4.4 Identify Systematic Weaknesses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198205ac",
   "metadata": {},
   "source": [
    "#### 4.5 Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66557fa8",
   "metadata": {},
   "source": [
    "##### 4.5.1 F1 Score by Entity Type (Bar Chart)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96924a3",
   "metadata": {},
   "source": [
    "##### 4.5.2 Entity Frequency vs F1 Score (Scatter Plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b7aa64",
   "metadata": {},
   "source": [
    "##### 4.5.3 Confusion Matrix Heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1da6e09",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36bd6f3",
   "metadata": {},
   "source": [
    "### 5. Error Analysis Framework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffdf5de",
   "metadata": {},
   "source": [
    "#### 5.1 Boundary Error Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1732d02b",
   "metadata": {},
   "source": [
    "##### 5.1.1 Partial Match Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8207bf1",
   "metadata": {},
   "source": [
    "##### 5.1.2 Exact Match vs Partial Match Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92f8b29",
   "metadata": {},
   "source": [
    "#### 5.2 Entity Type Confusion Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32848735",
   "metadata": {},
   "source": [
    "##### 5.2.1 Build Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e60865",
   "metadata": {},
   "source": [
    "##### 5.2.2 Common Confusion Patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23325f38",
   "metadata": {},
   "source": [
    "#### 5.3 Multi-token Entity Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dee1923",
   "metadata": {},
   "source": [
    "##### 5.3.1 Single-token vs Multi-token Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d0226a",
   "metadata": {},
   "source": [
    "##### 5.3.2 Entity Length Impact on F1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3625d0",
   "metadata": {},
   "source": [
    "#### 5.4 Error Examples Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d504bf77",
   "metadata": {},
   "source": [
    "##### 5.4.1 Sample Mispredictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb98344",
   "metadata": {},
   "source": [
    "##### 5.4.2 Error Categorization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8823d363",
   "metadata": {},
   "source": [
    "##### 5.4.3 Pattern Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70cbc6c4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c531c90e",
   "metadata": {},
   "source": [
    "### 6. Confidence Score Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084d4751",
   "metadata": {},
   "source": [
    "#### 6.1 Extract Prediction Confidence Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430df535",
   "metadata": {},
   "source": [
    "#### 6.2 Confidence Distribution Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001b1406",
   "metadata": {},
   "source": [
    "##### 6.2.1 Correct vs Incorrect Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066c1354",
   "metadata": {},
   "source": [
    "##### 6.2.2 Average Confidence by Prediction Type (TP/FP/FN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd903034",
   "metadata": {},
   "source": [
    "#### 6.3 Threshold Analysis for Production"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd84f16",
   "metadata": {},
   "source": [
    "##### 6.3.1 Test Multiple Thresholds [0.5, 0.6, 0.7, 0.8, 0.85, 0.9, 0.95]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0082412d",
   "metadata": {},
   "source": [
    "##### 6.3.2 Precision/Coverage/Recall at Each Threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8609c9ea",
   "metadata": {},
   "source": [
    "#### 6.4 Precision-Coverage Tradeoff Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93b5fe1",
   "metadata": {},
   "source": [
    "#### 6.5 Production Threshold Recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1e9ffe",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a7ff8a",
   "metadata": {},
   "source": [
    "### 7. Inference Speed & Scalability Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0fffe5",
   "metadata": {},
   "source": [
    "#### 7.1 Measure Inference Latency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa0336d",
   "metadata": {},
   "source": [
    "##### 7.1.1 Per Document (Batch Size = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e465d725",
   "metadata": {},
   "source": [
    "##### 7.1.2 Per Batch (Batch Size = 8, 16, 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ed1e13",
   "metadata": {},
   "source": [
    "#### 7.2 Memory Profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eefdfd2",
   "metadata": {},
   "source": [
    "##### 7.2.1 GPU Memory During Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e3bd04",
   "metadata": {},
   "source": [
    "##### 7.2.2 GPU Memory During Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ffee15",
   "metadata": {},
   "source": [
    "##### 7.2.3 CPU Inference Feasibility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428aac09",
   "metadata": {},
   "source": [
    "#### 7.3 Throughput Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6817c5",
   "metadata": {},
   "source": [
    "##### 7.3.1 Documents per Second"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf448cd",
   "metadata": {},
   "source": [
    "##### 7.3.2 Large-scale Processing Estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3ab4c7",
   "metadata": {},
   "source": [
    "#### 7.4 Scalability Considerations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1644ff",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46374a1",
   "metadata": {},
   "source": [
    "### 8. Production-Readiness Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d0206c",
   "metadata": {},
   "source": [
    "#### 8.1 Clinical Coding Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94399f3a",
   "metadata": {},
   "source": [
    "##### 8.1.1 Auto-code vs Manual Review Decision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496413a6",
   "metadata": {},
   "source": [
    "##### 8.1.2 Automation Rate at Different Thresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713e562a",
   "metadata": {},
   "source": [
    "#### 8.2 High-Value Entity Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb56776",
   "metadata": {},
   "source": [
    "##### 8.2.1 F1 on Critical Entities (Disease_disorder, Therapeutic_procedure, Medication)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1de0ec",
   "metadata": {},
   "source": [
    "##### 8.2.2 Precision on High-Value Entities at 0.85 Confidence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88085ae",
   "metadata": {},
   "source": [
    "#### 8.3 False Positive Impact Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670aada7",
   "metadata": {},
   "source": [
    "##### 8.3.1 FP Rate by Entity Type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d62bdae",
   "metadata": {},
   "source": [
    "##### 8.3.2 High-Risk Entity Identification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebee592",
   "metadata": {},
   "source": [
    "#### 8.4 Production Readiness Report Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096bc6cd",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c53ca15",
   "metadata": {},
   "source": [
    "### 9. Model Selection & Final Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be89dfee",
   "metadata": {},
   "source": [
    "#### 9.1 Best Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de5721c",
   "metadata": {},
   "source": [
    "##### 9.1.1 Selection Criteria & Tradeoffs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010d2b6b",
   "metadata": {},
   "source": [
    "##### 9.1.2 Justification Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2699c98",
   "metadata": {},
   "source": [
    "#### 9.2 Phase 1 Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d26207",
   "metadata": {},
   "source": [
    "##### 9.2.1 Training Results Comparison Table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff429800",
   "metadata": {},
   "source": [
    "##### 9.2.2 Key Visualizations Compilation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fc0105",
   "metadata": {},
   "source": [
    "##### 9.2.3 Error Analysis Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a27afc",
   "metadata": {},
   "source": [
    "##### 9.2.4 Production Metrics Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d89345",
   "metadata": {},
   "source": [
    "#### 9.3 Model Artifacts Export"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f01330e",
   "metadata": {},
   "source": [
    "##### 9.3.1 Save Best Checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cafdfc9",
   "metadata": {},
   "source": [
    "##### 9.3.2 Save Tokenizer & Mappings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11aad4d7",
   "metadata": {},
   "source": [
    "##### 9.3.3 Save Evaluation Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f890a5",
   "metadata": {},
   "source": [
    "#### 9.4 Phase 1 Insights Document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841b01b2",
   "metadata": {},
   "source": [
    "##### 9.4.1 Key Findings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ae0458",
   "metadata": {},
   "source": [
    "##### 9.4.2 Surprising Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b5ea49",
   "metadata": {},
   "source": [
    "##### 9.4.3 Recommendations for Phase 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb08e38",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbd046c",
   "metadata": {},
   "source": [
    "### 10. Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d13a12",
   "metadata": {},
   "source": [
    "#### 10.1 Utility Functions Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d27c46",
   "metadata": {},
   "source": [
    "#### 10.2 Hyperparameter Log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f168207",
   "metadata": {},
   "source": [
    "#### 10.3 Raw Results Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17445701",
   "metadata": {},
   "source": [
    "#### 10.4 Additional Visualizations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
